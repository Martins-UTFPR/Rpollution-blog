---
title: Coletando dados da CETESB
author: William Amorim
date: '2018-03-16'
slug: scraper-cetesb
type: "post"
featured: "scraper-cetesb.png"
featuredalt: "Dados"
featuredpath: "img/2018"
categories: ["Coleta de dados"]
tags:
  - CETESB
  - São Paulo
  - Brasil
---



<p>Conversando com um colega irlandês, ele me disse que <strong>os melhores web scrapers devem ser brasileiros</strong>. Isso não é uma coisa legal.</p>
<p>Web scraping (ou raspagem web) é a <em>arte</em> de se coletar dados da internet. A necessidade de se raspar uma página web surge quando baixar manualmente as informações que queremos analisar se torna uma tarefa chata, demorada ou até mesmo inexequível.</p>
<p>Por princípio, dados públicos deveriam ser sempre acessíveis e disponibilizados prontos para análise. No entanto, por motivação política, desconhecimento de engenharia e análise de dados ou mera falta de interesse, é muito comum termos dados públicos escondidos atrás captchas ou sistemas ineficientes. E os órgãos públicos brasileiros são especialistas nisso.</p>
<p>O objetivo deste post é discutir ideias gerais sobre web scraping e usá-las para constuir um scraper para coletar dados de poluição do ar da CETESB.</p>
<div id="qualar" class="section level1">
<h1>Qualar</h1>
<p>O <a href="http://qualar.cetesb.sp.gov.br/qualar/home.do">Qualar</a> é o sistema de informações de qualidade do ar da CETESB. Por meio dele, podemos acessar os dados de todas as estações de monitoramento do estado de Sâo Pauo. O sistema exige a criação de um login e então o envio de um pequeno formulário com quais informações você gostaria de visualizar.</p>
<p>O Qualar funciona muito bem para pequenas consultas, mas na extração de uma massa grande de dados existem duas dificuldades:</p>
<ol style="list-style-type: decimal">
<li><p>Se você precisa de dados de várias estações e de vários poluente, você precisará repetir esse processo para cada combinação de estação/poluente. Pegar todos os dados de ozônio da Grande São Paulo, por exemplo, exigiria repetir a solicitação 23 vezes.</p></li>
<li><p>Como a planilha é impressa na tela, se você precisar de uma série muito longa, você vai demorar bastante para carregar a página e seu computador corre um grande risco de travar no meio do caminho por falta de RAM.</p></li>
</ol>
<p>Para contornar este problema, vamos usar o R para construir um código que simule uma requisição de dados ao Qualar. Em seguida, vamos transformar o código numa função para replicar o processo para diversos parâmetros rodando apenas algumas linhas de códigos.</p>
<p><strong>Observação</strong>: o sistema também tem uma opção “Exportar dados Avançado”. Nela, é possível escolher até 3 parâmetros para cada estação e os dados não são impressos na tela, sendo gerado diretamente um arquivo csv para download. Porém, com a desculpa de praticar a construção do scraper, não vamos usar essa opção.</p>
</div>
<div id="construindo-o-scraper" class="section level1">
<h1>Construindo o scraper</h1>
<p>Para construir o scraper, vamos seguir os passos definidos <a href="http://curso-r.com/blog/2017/05/19/2017-05-19-scrapper-ssp/">neste post</a> da Curso-R escrito pelo <a href="https://github.com/azeloc">Fernando Corrêa</a>. São eles:</p>
<ol style="list-style-type: decimal">
<li>Definir a página que você quer raspar.</li>
<li>Identificar exatamente as requisições que produzem o que você quer.</li>
<li>Construir um programa que imite as requisições que você faria manualmente.</li>
<li>Repitir o passo (3) quantas vezes quiser.</li>
</ol>
<p>Um fluxo mais estruturado do web scraping é discutido <a href="http://curso-r.com/blog/2018/02/18/2018-02-18-fluxo-scraping/">neste post</a> do <a href="https://github.com/ctlente/">Caio Lente</a>.</p>
<div id="passo-1" class="section level2">
<h2>PASSO 1</h2>
<p>Para chegar na página que queremos raspar, precisamos passar pelas seguintes etapas dentro do Qualar: login, pesquisa e janela com os dados. Veja abaixo como prosseguir.</p>
<p><strong>Login</strong>: fazer o login <a href="http://qualar.cetesb.sp.gov.br/qualar/home.do">na página inicial</a>.</p>
<p><img src="/img/blog/scraper-cetesb/qualar_login.png" style="display: block; margin: auto;" /></p>
<p><strong>Pesquisa</strong>: na próxima página, acessar “Consultas/Exportar Dados” no menu da esquerda e preencher a pesquisa com os dados do parâmetro que você quer acessar.</p>
<p><img src="/img/blog/scraper-cetesb/qualar_form.png" style="display: block; margin: auto;" /></p>
<p><strong>Dados</strong>: na nova janela aberta pelo site estão os dados que queremos raspar.</p>
<p><img src="/img/blog/scraper-cetesb/qualar_dados.png" style="display: block; margin: auto;" /></p>
<p><br></p>
</div>
<div id="passo-2" class="section level2">
<h2>PASSO 2</h2>
<p>Para descobrir qual requisição é feita em cada momento, podemos utilizar o “Inspect element” do navegador. Eu estou usando o Firefox neste post, mas o procedimento é semelhante em outros navegarores.</p>
<p>O login é uma submissão de formulário. Inspecionando o html da página, podemos ver que os itens que o formulário precisa enviar são o “cetesb_login” e o “cetesb_passoword”.</p>
<p><img src="/img/blog/scraper-cetesb/inspect-form-login.png" style="display: block; margin: auto;" /></p>
<p>Para descobrir que tipo de requisição o login faz, basta abrir o Inspect element antes de fazer o login, logar no site e olhar a aba “Network”. A requisição que queremos é a “autenticador”. Ela faz uma requisição POST para a url “<a href="http://qualar.cetesb.sp.gov.br/qualar/autenticador" class="uri">http://qualar.cetesb.sp.gov.br/qualar/autenticador</a>”.</p>
<p><img src="/img/blog/scraper-cetesb/inspect_login.png" style="display: block; margin: auto;" /></p>
<p>Não vou mostrar aqui, mas a requisição que a pesquisa faz para acessar os dados também é a submissão de um formulário e pode ser encontrada de forma equivalente.</p>
<p>Assim, para acessar os dados, precisaremos enviar outra requisição POST, agora para a url “<a href="http://qualar.cetesb.sp.gov.br/qualar/exportaDados.do" class="uri">http://qualar.cetesb.sp.gov.br/qualar/exportaDados.do</a>”, contendo os itens desse novo formulário, que são as informações que preencheríamos na pesquisa. No próximo passo, vai ficar mais claro o que estamos fazendo nessa etapa.</p>
</div>
<div id="passo-3" class="section level2">
<h2>PASSO 3</h2>
<p>Vamos criar um código que imite essas requisições.</p>
<p>Primeiro, como o sistema Qualar exige login, precisamos capturar o cookie do site para <em>manter a sessão logada</em> nas requisições seguintes. O cookie da sessão é guardado no objeto <code>my_cookie</code>, que será passado em todas as requisições.</p>
<pre class="r"><code>library(magrittr)
library(httr)

res &lt;- GET(&quot;http://qualar.cetesb.sp.gov.br/qualar/home.do&quot;)
my_cookie &lt;- cookies(res)$value %&gt;% purrr::set_names(cookies(res)$name)</code></pre>
<p>Agora, precisamos enviar a requisição POST para fazer o login e acessar o sistema.</p>
<ul>
<li><p>Os parâmetros do formulário são colocados dentro do argumento <code>body=</code> da função <code>POST()</code>. Se você estiver replicando, basta substituir os valores <code>seu_login</code> e <code>sua_senha</code> pelo login e senha que você obteve ao se cadastrar no Qualar.</p></li>
<li><p>O argumento <code>encode = &quot;form&quot;</code> especifica que a requisição é uma submissão de formulário.</p></li>
<li><p>O parâmetro <code>enviar = &quot;OK&quot;</code> indica que estamos submetendo o formulário.</p></li>
<li><p>O cookie é passado usando a função <code>set_cookies()</code>.</p></li>
</ul>
<pre class="r"><code>url &lt;- &quot;http://qualar.cetesb.sp.gov.br/qualar/autenticador&quot;

res &lt;- POST(
  url, 
  body = list(
    cetesb_login = &quot;seu_login&quot;,
    cetesb_password = &quot;sua_senha&quot;,
    enviar = &quot;OK&quot;
  ), 
  encode = &quot;form&quot;,
  set_cookies(my_cookie)
)</code></pre>
<p>Então fazemos uma requisão POST para acessar os dados. Essa requisição imita a pesqusia dentro da página “Exportar dados”. Nela, precisamos definir quais dados queremos acessar.</p>
<pre class="r"><code>url &lt;- &quot;http://qualar.cetesb.sp.gov.br/qualar/exportaDados.do&quot;

res &lt;- POST(
  url,
  query = list(method = &quot;pesquisar&quot;),
  body = list(
    irede = &quot;A&quot;,
    dataInicialStr  = &quot;04/03/2018&quot;,
    dataFinalStr = &quot;05/03/2018&quot;,
    cDadosInvalidos = &quot;on&quot;,
    iTipoDado = &quot;P&quot;,
    estacaoVO.nestcaMonto = &quot;72&quot;,
    parametroVO.nparmt = &quot;63&quot;
  ),
  encode = &quot;form&quot;,
  set_cookies(my_cookie)
)</code></pre>
<p>Observe que, apesar de na pesquisa conseguirmos selecionar o nome da estação e do parâmetro, a requisição envia ids numéricos. No Qualar, eu encontrei apenas os ids das estações, mas os valores de ambos os parâmetros podem ser encontrados inspecionando o html da página. Para facilitar a nossa vida, eu salvei esses valores nos arquivos <code>station_ids.csv</code> e <code>param_ids.csv</code>, que podem ser baixados pelo <a href="https://github.com/williamorim/Rpollution-blog/tree/master/content/blog/data">repositório do blog no Github</a>.</p>
<pre class="r"><code>readr::read_csv(&quot;data/station_ids.csv&quot;)
## # A tibble: 62 x 3
##       id stationname                initial_date
##    &lt;int&gt; &lt;chr&gt;                      &lt;chr&gt;       
##  1    65 Mauá                       01/01/1998  
##  2    66 Cubatão-V.Parisi           01/01/1998  
##  3    67 Sorocaba                   01/01/1998  
##  4    73 Congonhas                  01/01/1998  
##  5    87 Cubatão-Centro             01/01/1998  
##  6    88 S.José Campos              01/01/1998  
##  7    89 Campinas-Centro            01/01/1998  
##  8    91 Cerqueira César            01/01/1998  
##  9    92 Diadema                    01/01/1998  
## 10    95 Cid.Universitária-USP-Ipen 01/01/1998  
## # ... with 52 more rows</code></pre>
<pre class="r"><code>readr::read_csv(&quot;data/param_ids.csv&quot;)
## # A tibble: 20 x 3
##       id param_abbrev param                              
##    &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;                              
##  1    61 BEN          Benzeno                            
##  2    16 CO           Monóxido de Carbono                
##  3    23 DV           Direção do Vento                   
##  4    21 DVG          Direção do Vento Global            
##  5    19 ERT          Enxofre Reduzido Total             
##  6    59 HCNM         Hidrocarbonetos Totais menos Metano
##  7    12 MP10         Partículas Inaláveis               
##  8    57 MP2.5        Partículas Inaláveis Finas         
##  9    17 NO           Monóxido de Nitrogênio             
## 10    15 NO2          Dióxido de Nitrogênio              
## 11    18 NOx          Óxidos de Nitrogênio               
## 12    63 O3           Ozônio                             
## 13    29 PRESS        Pressão Atmosférica                
## 14    26 RADG         Radiação Solar Global              
## 15    56 RADUV        Radiação Ultra-violeta             
## 16    13 SO2          Dióxido de Enxofre                 
## 17    25 TEMP         Temperatura do Ar                  
## 18    62 TOL          Tolueno                            
## 19    28 UR           Umidade Relativa do Ar             
## 20    24 VV           Velocidade do Vento</code></pre>
<p>Para finaliar, precisamos ler o resultado da nossa requisição e transformar a tabela existe no html em um data frame.</p>
<pre class="r"><code>content(res) %&gt;% 
  rvest::html_table(fill = TRUE) %&gt;%
  extract2(2)</code></pre>
</div>
<div id="passo-4" class="section level2">
<h2>Passo 4</h2>
<p>Agora, vamos transformar nosso código numa função para poder repetir o processo várias vezes para diversos parâmetros.</p>
<pre class="r"><code>scraper_CETESB &lt;- function(station, parameter, start, end, type = &quot;P&quot;, login, password, invalidData = &quot;on&quot;, network = &quot;A&quot;) {
  
  
  res &lt;- GET(&quot;http://qualar.cetesb.sp.gov.br/qualar/home.do&quot;)
  my_cookie &lt;- cookies(res)$value %&gt;% purrr::set_names(cookies(res)$name)
  
  url &lt;- &quot;http://qualar.cetesb.sp.gov.br/qualar/autenticador&quot;
  
  res &lt;- POST(
    url, 
    body = list(
      cetesb_login = login,
      cetesb_password = password,
      enviar = &quot;OK&quot;
    ), 
    encode = &quot;form&quot;,
    set_cookies(my_cookie)
  )
  
  url &lt;- &quot;http://qualar.cetesb.sp.gov.br/qualar/exportaDados.do&quot;
  
  res &lt;- POST(
    url,
    query = list(method = &quot;pesquisar&quot;),
    body = list(
      irede = network,
      dataInicialStr  = start,
      dataFinalStr = end,
      cDadosInvalidos = invalidData,
      iTipoDado = type,
      estacaoVO.nestcaMonto = station,
      parametroVO.nparmt = parameter
    ),
    encode = &quot;form&quot;,
    set_cookies(my_cookie)
  )
  
  content(res) %&gt;% 
  rvest::html_table(fill = TRUE) %&gt;%
  extract2(2)
  
}</code></pre>
<p>Assim, basta rodar a função abaixo com o seu login e senha para obter em alguns segundos uma tabela estruturada com os dados solicitados.</p>
<pre class="r"><code>scraper_CETESB(station = &quot;72&quot;, 
               parameter = &quot;63&quot;, 
               start = &quot;04/03/2018&quot;, 
               end = &quot;05/03/2018&quot;, 
               type = &quot;P&quot;, 
               login = &quot;seu_login&quot;, 
               password = &quot;sua_senha&quot;, 
               invalidData = &quot;on&quot;, 
               network = &quot;A&quot;)</code></pre>
<p>Iterando essa função fica fácil repetir o processo para diversas estações e parâmetros.</p>
</div>
</div>
<div id="observacoes" class="section level1">
<h1>Observações</h1>
<ul>
<li><p>Fazer um scraper exige um conhecimento não trivial sobre Web. Eu deixei vários pontos obscuros para não deixar o post muito denso e principalmente por não saber o suficiente para me aprofundar sem falar eventuais besteiras. Estou deixando várias referências para quem quiser tirar estudar o tema e fico à disposição para tirar dúvidas sobre o código.</p></li>
<li><p>Um scraper sempre será subordinado à estrutura do site. Se a CETESB mudar alguma coisa na estrutura do Qualar, esse código pode não funcionar mais e precisará ser adaptado ou até mesmo construído do zero.</p></li>
<li><p>Quando você estiver raspando dados da web, tome cuidado para não bombardear o servidor da página com requisições. Você pode acabar tendo o IP bloqueado ou derrubando o site.</p></li>
<li><p>Antes de fazer raspagem de sites particulares, leia sempre os Termos de uso para evitar problemas legais. A empresa ou responsável pelo site pode proibir a automatização de requisições.</p></li>
</ul>
</div>
<div id="agradecimentos" class="section level1">
<h1>Agradecimentos</h1>
<p>Agradecimento especial ao execelente <a href="https://github.com/dfalbel">Daniel Falbel</a> pela ajuda com o código e com web scraping.</p>
</div>
<div id="referencias" class="section level1">
<h1>Referências</h1>
<ul>
<li><p><a href="http://curso-r.com/blog/2018/02/18/2018-02-18-fluxo-scraping/">O fluxo do web scraping</a></p></li>
<li><p><a href="http://curso-r.com/blog/2017/05/19/2017-05-19-scrapper-ssp/">Web scraping do site da Secretaria de Segurança Pública de São Paulo</a></p></li>
<li><p><a href="http://curso-r.com/blog/2018/02/17/2018-02-17-scraper-distribuido/">Web Scraper Distribuído</a></p></li>
<li><p><a href="https://github.com/curso-r/201803-workshop-webscraping">Repositório do workshop de web scraping da Curso-R</a></p></li>
<li><p><a href="https://cran.r-project.org/web/packages/httr/vignettes/quickstart.html">Pacote httr</a></p></li>
<li><p><a href="https://github.com/hadley/rvest/blob/master/vignettes/selectorgadget.Rmd">Pacote rvest</a></p></li>
</ul>
</div>
<div id="vale-a-leitura" class="section level1">
<h1>Vale a leitura!</h1>
<ul>
<li><p><a href="http://curso-r.com/blog/2017/09/13/2017-09-13-brcrimr/">brcrimR</a></p></li>
<li><p><a href="http://curso-r.com/blog/2018/02/23/2018-02-21-2cents/">Meus 2 Centavos: análise das notas</a></p></li>
</ul>
</div>
