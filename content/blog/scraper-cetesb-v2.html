---
title: Nova versão do scraper da CETESB
author: William Amorim
date: '2019-07-20'
slug: scraper-cetesb
type: "post"
featured: "scraper-cetesb.png"
featuredalt: "Dados"
featuredpath: "img/2019"
categories: ["Coleta de dados"]
tags:
  - CETESB
  - São Paulo
  - Brasil
---



<p>Neste post, vou apresentar algumas mudanças no <a href="https://www.rpollution.com/blog/scraper-cetesb/">scraper em R que eu montei</a> para baixar os dados da CETESB a partir do Qualar.</p>
<div id="o-que-e-o-qualar" class="section level1">
<h1>O que é o Qualar?</h1>
<p>O <a href="http://qualar.cetesb.sp.gov.br/qualar/home.do">Qualar</a> é o sistema de informações de qualidade do ar da CETESB. Por meio dele, podemos acessar os dados de todas as estações de monitoramento do estado de São Paulo. O sistema exige a criação de um login e então o envio de um pequeno formulário com quais informações você gostaria de visualizar.</p>
<p>O Qualar funciona muito bem para pequenas consultas, mas na extração de várias estações ou parâmetros o trabalho se torna maçante.</p>
<p>O scraper contorna esse problema, simulando requisições de dados ao Qualar que podem ser facilmente iteradas para diversas estações e parâmetros.</p>
</div>
<div id="o-pacote-rpollution" class="section level1">
<h1>O pacote Rpollution</h1>
<p>A principal mudança nessa nova versão é onde a função <code>scraper_cetesb()</code> passará a morar. Anteriormente, ela estava no pacote <code>koffing</code>, encontrado <a href="https://github.com/atmoschem/koffing">neste repositório</a> da organização <code>atmoschem</code>.</p>
<p>Agora, ele passará a morar no pacote <code>Rpollution</code>, encontrado <a href="https://github.com/williamorim/Rpollution">neste repositório</a>. Eu resolvi fazer essa mudança pois quero reviver o <code>Rpollution</code>, criando ferramentas mais gerais para trabalhar com dados de poluição, além de apenas web scrapers.</p>
<p>A versão do pacote <code>koffing</code> é a atual e continuará disponível, mas em algum momento eu deixarei de dar manutenção a ela.</p>
</div>
<div id="o-que-mudou-no-scraper" class="section level1">
<h1>O que mudou no scraper?</h1>
<ul>
<li><p>A função está muito mais rápida, pois utiliza agora a seção <em>Exportar Dados Avançado</em> que não imprime os dados na tela antes do download.</p></li>
<li><p>Os argumentos <code>type</code>, <code>invalidData</code> e <code>network</code> foram removidos.</p></li>
<li><p>Dois novos argumentos foram incluídos: <code>file</code> e <code>safe</code>.</p>
<ul>
<li>O argumento <code>file</code> permite salvar os dados diretamente em um arquivo, em vez de imprimir na tela ou salvar em um objeto do R.</li>
<li>O argumento <code>safe</code>, quando <code>TRUE</code>, impede que o scraper devolva um erro caso não consiga baixar os dados. Isso é útil quando a função é iterada para diversos parâmetros.</li>
</ul></li>
</ul>
</div>
<div id="exemplo" class="section level1">
<h1>Exemplo</h1>
<p>Para instalar o pacote <code>RPollution</code>, basta rodar o código abaixo.</p>
<pre class="r"><code>remotes::install_github(&quot;williamorim/Rpollution&quot;)

# Se você não tiver o pacote `remotes` instalado, rode este código antes:
install.packages(&quot;remotes&quot;)</code></pre>
<p>No exemplo abaixo, estamos baixando os dados de ozônio (63) para a estação Dom Pedro II (72) para o mês de janeiro de 2018. Os dados são guardados no objeto <code>dados_ozonio</code>.</p>
<pre class="r"><code>library(Rpollution)

dados_ozonio &lt;- scraper_cetesb(
  station = 72, 
  parameter = 63,
  start = &quot;01/01/2018&quot;, 
  end = &quot;31/01/2018&quot;,
  login = &quot;login&quot;, 
  password = &quot;senha&quot;
)</code></pre>
<p>Para esse código rodar de fato, você precisa substituir os argumentos <code>login</code> e <code>password</code> com os seus dados de cadastro do Qualar.</p>
<p>Se quiséssemos agora baixar os dados tanto de ozônio quanto de NO2 (15), poderíamos fazer um <code>for</code>, iterando no valor do argumento <code>parameter</code>.</p>
<pre class="r"><code>parametros &lt;- c(15, 63)

for(i in parametros) {
  
  dados_ozonio &lt;- scraper_cetesb(
  station = 72, 
  parameter = i,
  start = &quot;01/01/2018&quot;, 
  end = &quot;31/01/2018&quot;,
  login = &quot;login&quot;, 
  password = &quot;senha&quot;,
  file = paste0(&quot;dados_&quot;, i, &quot;.rds&quot;),
  safe = TRUE
)
  
}</code></pre>
<p>Nesse exemplo, os dados são guardados agora em arquivos, um para cada poluente. Isso é feito a partir do parâmetro <code>file</code>, que recebe uma string com o nome do arquivo em formato <code>.rds</code>.</p>
<p>Além disso, repare que adicionamos o argumento <code>safe = TRUE</code>. Isso impede que o R retorne um erro caso o scraper não consiga baixar os dados para um dos poluentes, interrompendo a execução do <code>for</code> pela metade. Dessa forma, ele sempre vai tentar baixar os dados para todos os poluentes selecionados no objeto <code>parametros</code>.</p>
<blockquote>
<p>Web scrapers são altamente vulneráveis a alterações no site em que estão raspando. Se você encontrar algum erro ou o scraper parar de funcionar, por favor me avise. :)</p>
</blockquote>
</div>
<div id="referencias" class="section level1">
<h1>Referências</h1>
<ul>
<li><p><a href="http://curso-r.com/blog/2018/02/18/2018-02-18-fluxo-scraping/">O fluxo do web scraping</a></p></li>
<li><p><a href="http://curso-r.com/blog/2018/02/17/2018-02-17-scraper-distribuido/">Web Scraper Distribuído</a></p></li>
<li><p><a href="https://github.com/curso-r/201904-workshop-web-scraping">Repositório do workshop de web scraping da Curso-R</a></p></li>
</ul>
</div>
